{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Description of Code, this code is AI-generated**\n",
        "Demucs audio seperation was the main bottlneck of this project, it required a lot of GPU hours-, this code takes the raw audio clips and separates them into vocals and non vocals stem and zips them out to GDrive. It includes heavy multiprocessing, multiple batches processsing at the same time, this is the code for negative splitting a similar code was used for the positive clips.\n"
      ],
      "metadata": {
        "id": "E6cvCqr_TJ70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXTaK6jBwgLT"
      },
      "outputs": [],
      "source": [
        "pip install -U demucs torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8XrjQpvBwEhT"
      },
      "outputs": [],
      "source": [
        "*\n",
        "\n",
        "# ================= üì¶ IMPORTS =================\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import glob\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import gc\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "\n",
        "# ================= ‚öôÔ∏è CONFIGURATION =================\n",
        "\n",
        "INPUT_BASE_FOLDER = \"/content/drive/MyDrive/negative_dataset_48k\"\n",
        "OUTPUT_BASE_FOLDER = \"/content/drive/MyDrive/separated_audio_negative\"\n",
        "OUTPUT_BATCH_SIZE = 1000\n",
        "DEMUCS_BATCH_SIZE = 1000\n",
        "NUM_PARALLEL_BATCHES = 10\n",
        "NUM_JOBS = 2\n",
        "\n",
        "# Local folders\n",
        "LOCAL_STAGING_BASE = \"/content/staging_negative\"\n",
        "CHECKPOINT_FILE = None\n",
        "\n",
        "# Model settings\n",
        "MODEL_NAME = \"htdemucs\"\n",
        "DEVICE = \"cuda\"\n",
        "\n",
        "# Game folder mapping\n",
        "GAME_PROCESSING_ORDER = [\"Valorant\", \"CS2\", \"Apex\"]\n",
        "GAME_FOLDERS = {\n",
        "    \"valorant_set\": \"Valorant\",\n",
        "    \"cs2_set\": \"CS2\",\n",
        "    \"apex_set\": \"Apex\"\n",
        "}\n",
        "\n",
        "# Timeout\n",
        "DEMUCS_TIMEOUT_PER_FILE = 30\n",
        "\n",
        "# Lock for thread-safe operations\n",
        "checkpoint_lock = threading.Lock()\n",
        "staging_lock = threading.Lock()\n",
        "\n",
        "# Known error patterns\n",
        "BAD_FILE_ERRORS = [\n",
        "    \"AssertionError\", \"pad1d\", \"RuntimeError\", \"Invalid data\",\n",
        "    \"corrupted\", \"Could not find a format\", \"Invalid audio\",\n",
        "    \"Error opening\", \"No such file\",\n",
        "]\n",
        "\n",
        "# ================= üîß SETUP =================\n",
        "def setup_colab():\n",
        "    print(\"üîå Setting up...\")\n",
        "    if not os.path.exists(\"/content/drive\"):\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    if not os.path.exists(INPUT_BASE_FOLDER):\n",
        "        print(f\"‚ùå ERROR: Input folder not found: {INPUT_BASE_FOLDER}\")\n",
        "        return False\n",
        "\n",
        "    global CHECKPOINT_FILE\n",
        "    CHECKPOINT_FILE = os.path.join(OUTPUT_BASE_FOLDER, \"negative_parallel_checkpoint.json\")\n",
        "    print(\"‚úÖ Ready!\")\n",
        "    return True\n",
        "\n",
        "def verify_gpu():\n",
        "    result = subprocess.run([sys.executable, \"-c\", \"\"\"\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"OK:{torch.cuda.get_device_name(0)}:{torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}\")\n",
        "else:\n",
        "    print(\"NO_GPU\")\n",
        "\"\"\"], capture_output=True, text=True)\n",
        "\n",
        "    if \"OK:\" in result.stdout:\n",
        "        parts = result.stdout.strip().split(\":\")\n",
        "        print(f\"‚úÖ GPU: {parts[1]} ({parts[2]} GB)\")\n",
        "        print(f\"‚ö° Running {NUM_PARALLEL_BATCHES} parallel batches!\")\n",
        "        return True\n",
        "    print(\"‚ö†Ô∏è No GPU - using CPU\")\n",
        "    return False\n",
        "\n",
        "def setup_folders():\n",
        "    os.makedirs(OUTPUT_BASE_FOLDER, exist_ok=True)\n",
        "    for game in GAME_PROCESSING_ORDER:\n",
        "        os.makedirs(os.path.join(OUTPUT_BASE_FOLDER, f\"{game}_Separated\"), exist_ok=True)\n",
        "\n",
        "# ================= üíæ CHECKPOINT =================\n",
        "def load_checkpoint():\n",
        "    if CHECKPOINT_FILE and os.path.exists(CHECKPOINT_FILE):\n",
        "        try:\n",
        "            with open(CHECKPOINT_FILE, 'r') as f:\n",
        "                cp = json.load(f)\n",
        "            if isinstance(cp.get(\"processed_clips\"), list):\n",
        "                cp[\"processed_clips\"] = set(cp[\"processed_clips\"])\n",
        "            if isinstance(cp.get(\"bad_files\"), list):\n",
        "                cp[\"bad_files\"] = set(cp[\"bad_files\"])\n",
        "            print(f\"üì• Checkpoint: {cp.get('total_processed', 0)} done, {len(cp.get('bad_files', []))} bad\")\n",
        "            return cp\n",
        "        except:\n",
        "            pass\n",
        "    return {\n",
        "        \"processed_zips\": [],\n",
        "        \"processed_clips\": set(),\n",
        "        \"bad_files\": set(),\n",
        "        \"batch_numbers\": {\"Valorant\": 1, \"CS2\": 1, \"Apex\": 1},\n",
        "        \"total_processed\": 0,\n",
        "        \"total_skipped\": 0,\n",
        "    }\n",
        "\n",
        "def save_checkpoint(cp):\n",
        "    if not CHECKPOINT_FILE:\n",
        "        return\n",
        "    with checkpoint_lock:\n",
        "        cp_save = cp.copy()\n",
        "        cp_save[\"processed_clips\"] = list(cp.get(\"processed_clips\", set()))\n",
        "        cp_save[\"bad_files\"] = list(cp.get(\"bad_files\", set()))\n",
        "        cp_save[\"last_save\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        try:\n",
        "            os.makedirs(os.path.dirname(CHECKPOINT_FILE), exist_ok=True)\n",
        "            with open(CHECKPOINT_FILE, 'w') as f:\n",
        "                json.dump(cp_save, f)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# ================= üöÄ PARALLEL BATCH PROCESSING =================\n",
        "def process_single_batch(batch_id, file_list, staging_folder, pbar):\n",
        "    \"\"\"Process a single batch - called in parallel.\"\"\"\n",
        "    if not file_list:\n",
        "        return [], [], batch_id\n",
        "\n",
        "    temp_output = f\"/content/demucs_p{batch_id}_{int(time.time())}\"\n",
        "    timeout = DEMUCS_TIMEOUT_PER_FILE * len(file_list) + 120\n",
        "\n",
        "    cmd = [\n",
        "        sys.executable, \"-m\", \"demucs\",\n",
        "        \"-d\", DEVICE,\n",
        "        \"-j\", str(NUM_JOBS),\n",
        "        \"--two-stems=vocals\",\n",
        "        \"-n\", MODEL_NAME,\n",
        "        \"--mp3\", \"--mp3-bitrate\", \"320\",\n",
        "        \"-o\", temp_output\n",
        "    ]\n",
        "    cmd.extend(file_list)\n",
        "\n",
        "    successful = []\n",
        "    bad_files = []\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            # Collect outputs\n",
        "            for file_path in file_list:\n",
        "                name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "                vocals = os.path.join(temp_output, MODEL_NAME, name, \"vocals.mp3\")\n",
        "                no_vocals = os.path.join(temp_output, MODEL_NAME, name, \"no_vocals.mp3\")\n",
        "\n",
        "                if os.path.exists(vocals) and os.path.exists(no_vocals):\n",
        "                    with staging_lock:\n",
        "                        clip_folder = os.path.join(staging_folder, name)\n",
        "                        os.makedirs(clip_folder, exist_ok=True)\n",
        "                        shutil.copy2(vocals, os.path.join(clip_folder, \"vocals.mp3\"))\n",
        "                        shutil.copy2(no_vocals, os.path.join(clip_folder, \"no_vocals.mp3\"))\n",
        "                    successful.append(name)\n",
        "                    pbar.update(1)\n",
        "                else:\n",
        "                    bad_files.append(name)\n",
        "                    pbar.update(1)\n",
        "        else:\n",
        "            # Check for bad file errors\n",
        "            stderr = result.stderr or \"\"\n",
        "            if any(err.lower() in stderr.lower() for err in BAD_FILE_ERRORS):\n",
        "                # Process one by one to find bad file\n",
        "                for file_path in file_list:\n",
        "                    name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "                    single_out = f\"/content/demucs_single_{batch_id}_{int(time.time())}\"\n",
        "\n",
        "                    single_cmd = [\n",
        "                        sys.executable, \"-m\", \"demucs\",\n",
        "                        \"-d\", DEVICE, \"-j\", \"1\",\n",
        "                        \"--two-stems=vocals\", \"-n\", MODEL_NAME,\n",
        "                        \"--mp3\", \"-o\", single_out, file_path\n",
        "                    ]\n",
        "\n",
        "                    try:\n",
        "                        single_result = subprocess.run(single_cmd, capture_output=True,\n",
        "                                                       text=True, timeout=60)\n",
        "                        if single_result.returncode == 0:\n",
        "                            vocals = os.path.join(single_out, MODEL_NAME, name, \"vocals.mp3\")\n",
        "                            no_vocals = os.path.join(single_out, MODEL_NAME, name, \"no_vocals.mp3\")\n",
        "                            if os.path.exists(vocals) and os.path.exists(no_vocals):\n",
        "                                with staging_lock:\n",
        "                                    clip_folder = os.path.join(staging_folder, name)\n",
        "                                    os.makedirs(clip_folder, exist_ok=True)\n",
        "                                    shutil.copy2(vocals, os.path.join(clip_folder, \"vocals.mp3\"))\n",
        "                                    shutil.copy2(no_vocals, os.path.join(clip_folder, \"no_vocals.mp3\"))\n",
        "                                successful.append(name)\n",
        "                            else:\n",
        "                                bad_files.append(name)\n",
        "                        else:\n",
        "                            bad_files.append(name)\n",
        "                    except:\n",
        "                        bad_files.append(name)\n",
        "                    finally:\n",
        "                        if os.path.exists(single_out):\n",
        "                            shutil.rmtree(single_out, ignore_errors=True)\n",
        "                    pbar.update(1)\n",
        "            else:\n",
        "                for f in file_list:\n",
        "                    bad_files.append(os.path.splitext(os.path.basename(f))[0])\n",
        "                    pbar.update(1)\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        for f in file_list:\n",
        "            bad_files.append(os.path.splitext(os.path.basename(f))[0])\n",
        "            pbar.update(1)\n",
        "    except Exception as e:\n",
        "        for f in file_list:\n",
        "            bad_files.append(os.path.splitext(os.path.basename(f))[0])\n",
        "            pbar.update(1)\n",
        "    finally:\n",
        "        if os.path.exists(temp_output):\n",
        "            shutil.rmtree(temp_output, ignore_errors=True)\n",
        "\n",
        "    return successful, bad_files, batch_id\n",
        "\n",
        "\n",
        "def process_parallel_batches(file_list, staging_folder, checkpoint):\n",
        "    \"\"\"Process multiple batches in parallel using ThreadPoolExecutor.\"\"\"\n",
        "    if not file_list:\n",
        "        return [], []\n",
        "\n",
        "    all_successful = []\n",
        "    all_bad = []\n",
        "\n",
        "    # Split into chunks for parallel processing\n",
        "    chunks = []\n",
        "    for i in range(0, len(file_list), DEMUCS_BATCH_SIZE):\n",
        "        chunks.append(file_list[i:i + DEMUCS_BATCH_SIZE])\n",
        "\n",
        "    # Create progress bar for all files in super-batch\n",
        "    with tqdm(total=len(file_list), desc=\"   ‚ö° Processing\", leave=False,\n",
        "              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:\n",
        "\n",
        "        # Process chunks in parallel\n",
        "        with ThreadPoolExecutor(max_workers=NUM_PARALLEL_BATCHES) as executor:\n",
        "            futures = {}\n",
        "\n",
        "            for idx, chunk in enumerate(chunks):\n",
        "                future = executor.submit(process_single_batch, idx, chunk, staging_folder, pbar)\n",
        "                futures[future] = idx\n",
        "\n",
        "            for future in as_completed(futures):\n",
        "                try:\n",
        "                    successful, bad_files, batch_id = future.result()\n",
        "                    all_successful.extend(successful)\n",
        "                    all_bad.extend(bad_files)\n",
        "\n",
        "                    # Update checkpoint with bad files\n",
        "                    for bad in bad_files:\n",
        "                        checkpoint[\"bad_files\"].add(bad)\n",
        "\n",
        "                except Exception as e:\n",
        "                    tqdm.write(f\"   ‚ùå Batch error: {e}\")\n",
        "\n",
        "    return all_successful, all_bad\n",
        "\n",
        "    return all_successful, all_bad\n",
        "\n",
        "\n",
        "def count_staged(staging_folder):\n",
        "    if not os.path.exists(staging_folder):\n",
        "        return 0\n",
        "    count = 0\n",
        "    for item in os.listdir(staging_folder):\n",
        "        p = os.path.join(staging_folder, item)\n",
        "        if os.path.isdir(p) and os.path.exists(os.path.join(p, \"vocals.mp3\")):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "\n",
        "def flush_to_drive(game, batch_num, staging_folder, checkpoint):\n",
        "    if not os.path.exists(staging_folder):\n",
        "        return batch_num\n",
        "\n",
        "    clips = [d for d in os.listdir(staging_folder)\n",
        "             if os.path.isdir(os.path.join(staging_folder, d)) and\n",
        "             os.path.exists(os.path.join(staging_folder, d, \"vocals.mp3\"))]\n",
        "\n",
        "    if not clips:\n",
        "        return batch_num\n",
        "\n",
        "    print(f\"\\nüì§ [{game}] Uploading batch {batch_num} ({len(clips)} clips)...\")\n",
        "\n",
        "    game_output = os.path.join(OUTPUT_BASE_FOLDER, f\"{game}_Separated\")\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    zip_path = os.path.join(game_output, f\"{game}_Negative_Batch_{batch_num}_{len(clips)}clips_{timestamp}.zip\")\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "            for clip in clips:\n",
        "                clip_path = os.path.join(staging_folder, clip)\n",
        "                zf.write(os.path.join(clip_path, \"vocals.mp3\"), f\"{clip}/vocals.mp3\")\n",
        "                zf.write(os.path.join(clip_path, \"no_vocals.mp3\"), f\"{clip}/no_vocals.mp3\")\n",
        "                checkpoint[\"processed_clips\"].add(clip)\n",
        "\n",
        "        size_mb = os.path.getsize(zip_path) / (1024**2)\n",
        "        print(f\"   ‚úÖ Saved: {os.path.basename(zip_path)} ({size_mb:.1f} MB)\")\n",
        "\n",
        "        shutil.rmtree(staging_folder)\n",
        "        os.makedirs(staging_folder)\n",
        "\n",
        "        checkpoint[\"batch_numbers\"][game] = batch_num + 1\n",
        "        save_checkpoint(checkpoint)\n",
        "        gc.collect()\n",
        "\n",
        "        return batch_num + 1\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error: {e}\")\n",
        "        return batch_num\n",
        "\n",
        "\n",
        "# ================= üéÆ MAIN =================\n",
        "def run_pipeline():\n",
        "    print(\"=\" * 70)\n",
        "    print(\"üöÄ‚ö° ULTRA-FAST PARALLEL DEMUCS PIPELINE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"‚è∞ Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"‚ö° {NUM_PARALLEL_BATCHES} parallel batches √ó {DEMUCS_BATCH_SIZE} files = {NUM_PARALLEL_BATCHES * DEMUCS_BATCH_SIZE} files at once!\")\n",
        "    print(f\"üéØ Expected speed: ~0.8-1.2 sec per file (5x faster!)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if not setup_colab():\n",
        "        return\n",
        "\n",
        "    global DEVICE\n",
        "    if not verify_gpu():\n",
        "        DEVICE = \"cpu\"\n",
        "\n",
        "    setup_folders()\n",
        "    checkpoint = load_checkpoint()\n",
        "\n",
        "    if not isinstance(checkpoint.get(\"processed_clips\"), set):\n",
        "        checkpoint[\"processed_clips\"] = set(checkpoint.get(\"processed_clips\", []))\n",
        "    if not isinstance(checkpoint.get(\"bad_files\"), set):\n",
        "        checkpoint[\"bad_files\"] = set(checkpoint.get(\"bad_files\", []))\n",
        "\n",
        "    os.makedirs(LOCAL_STAGING_BASE, exist_ok=True)\n",
        "\n",
        "    # Scan game folders\n",
        "    game_zips = {g: [] for g in GAME_PROCESSING_ORDER}\n",
        "\n",
        "    for folder_name, game_name in GAME_FOLDERS.items():\n",
        "        folder_path = os.path.join(INPUT_BASE_FOLDER, folder_name)\n",
        "        if os.path.exists(folder_path):\n",
        "            zips = sorted(glob.glob(os.path.join(folder_path, \"*.zip\")))\n",
        "            game_zips[game_name] = zips\n",
        "            print(f\"üì¶ {game_name}: {len(zips)} zips\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    total_processed = checkpoint.get(\"total_processed\", 0)\n",
        "    total_skipped = checkpoint.get(\"total_skipped\", 0)\n",
        "\n",
        "    for game in GAME_PROCESSING_ORDER:\n",
        "        zips = game_zips[game]\n",
        "        if not zips:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n{'=' * 70}\")\n",
        "        print(f\"üéÆ {game.upper()} ({len(zips)} zips)\")\n",
        "        print(f\"{'=' * 70}\")\n",
        "\n",
        "        staging = os.path.join(LOCAL_STAGING_BASE, game)\n",
        "        os.makedirs(staging, exist_ok=True)\n",
        "\n",
        "        batch_num = checkpoint[\"batch_numbers\"].get(game, 1)\n",
        "\n",
        "        for src_zip in tqdm(zips, desc=f\"[{game}]\"):\n",
        "            zip_name = os.path.basename(src_zip)\n",
        "\n",
        "            if src_zip in checkpoint.get(\"processed_zips\", []):\n",
        "                continue\n",
        "\n",
        "            extract_dir = f\"/content/temp_neg_{game}\"\n",
        "            if os.path.exists(extract_dir):\n",
        "                shutil.rmtree(extract_dir)\n",
        "            os.makedirs(extract_dir)\n",
        "\n",
        "            try:\n",
        "                tqdm.write(f\"\\nüìÇ {zip_name}\")\n",
        "                with zipfile.ZipFile(src_zip, 'r') as zf:\n",
        "                    zf.extractall(extract_dir)\n",
        "\n",
        "                # Find audio files\n",
        "                audio_files = []\n",
        "                for root, _, files in os.walk(extract_dir):\n",
        "                    for f in sorted(files):\n",
        "                        if f.lower().endswith(('.m4a', '.mp3', '.wav', '.flac', '.ogg')):\n",
        "                            audio_files.append(os.path.join(root, f))\n",
        "\n",
        "                # Filter\n",
        "                files_to_process = [\n",
        "                    f for f in audio_files\n",
        "                    if os.path.splitext(os.path.basename(f))[0] not in checkpoint[\"processed_clips\"]\n",
        "                    and os.path.splitext(os.path.basename(f))[0] not in checkpoint[\"bad_files\"]\n",
        "                ]\n",
        "\n",
        "                skipped = len(audio_files) - len(files_to_process)\n",
        "                tqdm.write(f\"   üìÑ {len(audio_files)} files ({skipped} skipped)\")\n",
        "\n",
        "                if not files_to_process:\n",
        "                    checkpoint[\"processed_zips\"].append(src_zip)\n",
        "                    continue\n",
        "\n",
        "                # Process in parallel super-batches\n",
        "                super_batch_size = DEMUCS_BATCH_SIZE * NUM_PARALLEL_BATCHES\n",
        "\n",
        "                for i in range(0, len(files_to_process), super_batch_size):\n",
        "                    super_batch = files_to_process[i:i + super_batch_size]\n",
        "                    sb_idx = (i // super_batch_size) + 1\n",
        "                    total_sb = (len(files_to_process) + super_batch_size - 1) // super_batch_size\n",
        "\n",
        "                    tqdm.write(f\"   üöÄ Super-batch {sb_idx}/{total_sb} ({len(super_batch)} files in {NUM_PARALLEL_BATCHES} parallel)\")\n",
        "\n",
        "                    start_time = time.time()\n",
        "                    successful, bad = process_parallel_batches(super_batch, staging, checkpoint)\n",
        "                    elapsed = time.time() - start_time\n",
        "\n",
        "                    per_file = elapsed / len(super_batch) if super_batch else 0\n",
        "\n",
        "                    total_processed += len(successful)\n",
        "                    total_skipped += len(bad)\n",
        "\n",
        "                    for clip in successful:\n",
        "                        checkpoint[\"processed_clips\"].add(clip)\n",
        "\n",
        "                    tqdm.write(f\"   ‚úÖ {len(successful)} done ({per_file:.2f}s/file)\" +\n",
        "                              (f\", ‚ùå {len(bad)} bad\" if bad else \"\"))\n",
        "\n",
        "                    # Flush if staging is full\n",
        "                    if count_staged(staging) >= OUTPUT_BATCH_SIZE:\n",
        "                        batch_num = flush_to_drive(game, batch_num, staging, checkpoint)\n",
        "\n",
        "                    checkpoint[\"total_processed\"] = total_processed\n",
        "                    checkpoint[\"total_skipped\"] = total_skipped\n",
        "                    save_checkpoint(checkpoint)\n",
        "\n",
        "                checkpoint[\"processed_zips\"].append(src_zip)\n",
        "                save_checkpoint(checkpoint)\n",
        "\n",
        "            except zipfile.BadZipFile:\n",
        "                tqdm.write(f\"   ‚ùå Corrupted zip\")\n",
        "            except Exception as e:\n",
        "                tqdm.write(f\"   ‚ùå Error: {e}\")\n",
        "            finally:\n",
        "                if os.path.exists(extract_dir):\n",
        "                    shutil.rmtree(extract_dir, ignore_errors=True)\n",
        "\n",
        "        if count_staged(staging) > 0:\n",
        "            flush_to_drive(game, batch_num, staging, checkpoint)\n",
        "\n",
        "        print(f\"‚úÖ [{game}] Done!\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üéâ COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"‚úÖ Processed: {total_processed}\")\n",
        "    print(f\"‚ùå Skipped: {total_skipped}\")\n",
        "    print(f\"‚è∞ Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    for g in GAME_PROCESSING_ORDER:\n",
        "        out = os.path.join(OUTPUT_BASE_FOLDER, f\"{g}_Separated\")\n",
        "        if os.path.exists(out):\n",
        "            zips = glob.glob(os.path.join(out, \"*.zip\"))\n",
        "            mb = sum(os.path.getsize(z) for z in zips) / (1024**2)\n",
        "            print(f\"   üéÆ {g}: {len(zips)} batches ({mb:.1f} MB)\")\n",
        "\n",
        "# ================= üèÅ RUN =================\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}